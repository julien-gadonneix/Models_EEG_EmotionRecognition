{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "wdir = Path.cwd().parent.absolute()\n",
    "sys.path.insert(1, str(wdir))\n",
    "\n",
    "from models.EEGModels import EEGNet, ShallowConvNet, DeepConvNet, EEGNet_ChanRed, CapsEEGNet, TCNet\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block1.0.weight, Parameters: 1024\n",
      "Layer: block1.1.weight, Parameters: 64\n",
      "Layer: block1.1.bias, Parameters: 64\n",
      "Layer: block1.2.weight, Parameters: 7168\n",
      "Layer: block1.3.weight, Parameters: 512\n",
      "Layer: block1.3.bias, Parameters: 512\n",
      "Layer: block2.0.depthwise.weight, Parameters: 8192\n",
      "Layer: block2.0.pointwise.weight, Parameters: 32768\n",
      "Layer: block2.1.weight, Parameters: 64\n",
      "Layer: block2.1.bias, Parameters: 64\n",
      "Layer: dense.weight, Parameters: 512\n",
      "Layer: dense.bias, Parameters: 2\n",
      "Total Parameters: 50946\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet(nb_classes = 2, Chans = 14, Samples = 128, dropoutRate = 0.1, kernLength = 16, F1 = 64, D = 8, F2 = 64, dropoutType = 'Dropout')\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: chan_reduction.weight, Parameters: 1116\n",
      "Layer: chan_reduction.bias, Parameters: 18\n",
      "Layer: block1.0.weight, Parameters: 1600\n",
      "Layer: block1.1.weight, Parameters: 64\n",
      "Layer: block1.1.bias, Parameters: 64\n",
      "Layer: block1.2.weight, Parameters: 9216\n",
      "Layer: block1.3.weight, Parameters: 512\n",
      "Layer: block1.3.bias, Parameters: 512\n",
      "Layer: block2.0.depthwise.weight, Parameters: 8192\n",
      "Layer: block2.0.pointwise.weight, Parameters: 32768\n",
      "Layer: block2.1.weight, Parameters: 64\n",
      "Layer: block2.1.bias, Parameters: 64\n",
      "Layer: dense.weight, Parameters: 1152\n",
      "Layer: dense.bias, Parameters: 3\n",
      "Total Parameters: 55345\n"
     ]
    }
   ],
   "source": [
    "model_SEED = EEGNet_ChanRed(nb_classes = 3, Chans = 62, InnerChans=18, Samples = 200, dropoutRate = 0.1, kernLength = 25, F1 = 64, D = 8, F2 = 64, dropoutType = 'Dropout')\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_SEED.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2021/julien.gadonneix/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 1, 62, 200)\n",
    "y = model_SEED(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block_1_2.0.weight, Parameters: 512\n",
      "Layer: block_1_2.1.weight, Parameters: 8\n",
      "Layer: block_1_2.1.bias, Parameters: 8\n",
      "Layer: block_1_2.3.weight, Parameters: 224\n",
      "Layer: block_1_2.4.weight, Parameters: 16\n",
      "Layer: block_1_2.4.bias, Parameters: 16\n",
      "Layer: primaryCaps.caps.weight, Parameters: 24576\n",
      "Layer: primaryCaps.caps.bias, Parameters: 256\n",
      "Layer: primaryCaps.caps2.weight, Parameters: 69632\n",
      "Layer: primaryCaps.caps2.bias, Parameters: 256\n",
      "Layer: emotionCaps.W, Parameters: 1048576\n",
      "Layer: fc.weight, Parameters: 16\n",
      "Layer: fc.bias, Parameters: 1\n",
      "Total Parameters: 1144097\n"
     ]
    }
   ],
   "source": [
    "model_capseegnet = CapsEEGNet(nb_classes=2, Chans=14)\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_capseegnet.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n",
      "tensor([[0.4994, 0.5006],\n",
      "        [0.5017, 0.4983],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5015, 0.4985],\n",
      "        [0.4994, 0.5006],\n",
      "        [0.5004, 0.4996],\n",
      "        [0.5018, 0.4982]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 1, 14, 128)\n",
    "y = model_capseegnet(x)\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: PatchPartition.weight, Parameters: 5376\n",
      "Layer: PatchPartition.bias, Parameters: 32\n",
      "Layer: stages.0.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.0.WMSA.linear1.weight, Parameters: 3072\n",
      "Layer: stages.0.WMSA.linear1.bias, Parameters: 96\n",
      "Layer: stages.0.WMSA.linear2.weight, Parameters: 1024\n",
      "Layer: stages.0.WMSA.linear2.bias, Parameters: 32\n",
      "Layer: stages.0.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.0.SWMSA.linear1.weight, Parameters: 3072\n",
      "Layer: stages.0.SWMSA.linear1.bias, Parameters: 96\n",
      "Layer: stages.0.SWMSA.linear2.weight, Parameters: 1024\n",
      "Layer: stages.0.SWMSA.linear2.bias, Parameters: 32\n",
      "Layer: stages.0.ln.weight, Parameters: 32\n",
      "Layer: stages.0.ln.bias, Parameters: 32\n",
      "Layer: stages.0.MLP.ff.0.weight, Parameters: 4096\n",
      "Layer: stages.0.MLP.ff.0.bias, Parameters: 128\n",
      "Layer: stages.0.MLP.ff.2.weight, Parameters: 4096\n",
      "Layer: stages.0.MLP.ff.2.bias, Parameters: 32\n",
      "Layer: stages.1.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.1.WMSA.linear1.weight, Parameters: 12288\n",
      "Layer: stages.1.WMSA.linear1.bias, Parameters: 192\n",
      "Layer: stages.1.WMSA.linear2.weight, Parameters: 4096\n",
      "Layer: stages.1.WMSA.linear2.bias, Parameters: 64\n",
      "Layer: stages.1.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.1.SWMSA.linear1.weight, Parameters: 12288\n",
      "Layer: stages.1.SWMSA.linear1.bias, Parameters: 192\n",
      "Layer: stages.1.SWMSA.linear2.weight, Parameters: 4096\n",
      "Layer: stages.1.SWMSA.linear2.bias, Parameters: 64\n",
      "Layer: stages.1.ln.weight, Parameters: 64\n",
      "Layer: stages.1.ln.bias, Parameters: 64\n",
      "Layer: stages.1.MLP.ff.0.weight, Parameters: 16384\n",
      "Layer: stages.1.MLP.ff.0.bias, Parameters: 256\n",
      "Layer: stages.1.MLP.ff.2.weight, Parameters: 16384\n",
      "Layer: stages.1.MLP.ff.2.bias, Parameters: 64\n",
      "Layer: stages.2.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.WMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.WMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.WMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.WMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.SWMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.SWMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.SWMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.SWMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.ln.weight, Parameters: 128\n",
      "Layer: stages.2.ln.bias, Parameters: 128\n",
      "Layer: stages.2.MLP.ff.0.weight, Parameters: 65536\n",
      "Layer: stages.2.MLP.ff.0.bias, Parameters: 512\n",
      "Layer: stages.2.MLP.ff.2.weight, Parameters: 65536\n",
      "Layer: stages.2.MLP.ff.2.bias, Parameters: 128\n",
      "Layer: stages.3.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.3.WMSA.linear1.weight, Parameters: 196608\n",
      "Layer: stages.3.WMSA.linear1.bias, Parameters: 768\n",
      "Layer: stages.3.WMSA.linear2.weight, Parameters: 65536\n",
      "Layer: stages.3.WMSA.linear2.bias, Parameters: 256\n",
      "Layer: stages.3.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.3.SWMSA.linear1.weight, Parameters: 196608\n",
      "Layer: stages.3.SWMSA.linear1.bias, Parameters: 768\n",
      "Layer: stages.3.SWMSA.linear2.weight, Parameters: 65536\n",
      "Layer: stages.3.SWMSA.linear2.bias, Parameters: 256\n",
      "Layer: stages.3.ln.weight, Parameters: 256\n",
      "Layer: stages.3.ln.bias, Parameters: 256\n",
      "Layer: stages.3.MLP.ff.0.weight, Parameters: 262144\n",
      "Layer: stages.3.MLP.ff.0.bias, Parameters: 1024\n",
      "Layer: stages.3.MLP.ff.2.weight, Parameters: 262144\n",
      "Layer: stages.3.MLP.ff.2.bias, Parameters: 256\n",
      "Layer: PatchMerging.0.weight, Parameters: 32768\n",
      "Layer: PatchMerging.0.bias, Parameters: 64\n",
      "Layer: PatchMerging.1.weight, Parameters: 131072\n",
      "Layer: PatchMerging.1.bias, Parameters: 128\n",
      "Layer: PatchMerging.2.weight, Parameters: 524288\n",
      "Layer: PatchMerging.2.bias, Parameters: 256\n",
      "Layer: primaryCaps.caps.weight, Parameters: 3538944\n",
      "Layer: primaryCaps.caps.bias, Parameters: 384\n",
      "Layer: emotionCaps.W, Parameters: 98304\n",
      "Total Parameters: 5731528\n"
     ]
    }
   ],
   "source": [
    "model_tcnet = TCNet(nb_classes=2, device='cpu', Chans=14)\n",
    "\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_tcnet.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 14, 48, 128)\n",
    "out = model_tcnet(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1\n",
      "cuda\n",
      "True\n",
      "_CudaDeviceProperties(name='NVIDIA RTX A5000', major=8, minor=6, total_memory=24218MB, multi_processor_count=64)\n"
     ]
    }
   ],
   "source": [
    "print(os.cpu_count())\n",
    "print(torch.cuda.device_count()) \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(device.type == 'cuda')\n",
    "if device.type == 'cuda':\n",
    "    properties = torch.cuda.get_device_properties(device)\n",
    "    print(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'system_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m gpu_count \u001b[38;5;241m=\u001b[39m \u001b[43mget_gpu_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu_count \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of GPUs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gpu_count)\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mget_gpu_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get information about the GPU on macOS.\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run system_profiler command and capture the output\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem_profiler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-xml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSPDisplaysDataType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Parse the XML output\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     display_info \u001b[38;5;241m=\u001b[39m plistlib\u001b[38;5;241m.\u001b[39mloads(result\u001b[38;5;241m.\u001b[39mstdout)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib64/python3.9/subprocess.py:1837\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1836\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'system_profiler'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import plistlib\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"Get information about the GPU on macOS.\"\"\"\n",
    "    # Run system_profiler command and capture the output\n",
    "    result = subprocess.run(['system_profiler', '-xml', 'SPDisplaysDataType'], capture_output=True)\n",
    "    if result.returncode == 0:\n",
    "        # Parse the XML output\n",
    "        display_info = plistlib.loads(result.stdout)\n",
    "        # Extract GPU information\n",
    "        gpu_count = len(display_info[0]['_items'])\n",
    "        return gpu_count\n",
    "    else:\n",
    "        print(\"Error:\", result.stderr)\n",
    "        return None\n",
    "\n",
    "gpu_count = get_gpu_info()\n",
    "if gpu_count is not None:\n",
    "    print(\"Number of GPUs:\", gpu_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time:  0.7244799137115479\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# syncrocnize time with cpu, otherwise only time for oflaoding data to gpu would be measured\n",
    "torch.mps.synchronize()\n",
    "\n",
    "a = torch.ones(4000,4000, device=\"mps\")\n",
    "for _ in range(200):\n",
    "   a +=a\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print( \"GPU Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3296e+00, -1.7722e+00, -2.0000e+00, -1.2098e+00, -5.1593e-01,\n",
      "         -1.3994e-01,  3.0890e-01,  1.0507e+00],\n",
      "        [ 3.6133e-01,  1.3256e+00, -1.6759e-01, -1.1906e-01,  1.5129e+00,\n",
      "         -6.2672e-01,  5.7583e-01, -5.0284e-01],\n",
      "        [-4.0213e-01,  1.4174e+00,  1.0090e+00, -1.6705e+00, -5.1651e-01,\n",
      "          3.5122e-01,  1.4479e+00, -1.0237e+00],\n",
      "        [ 1.7625e-01, -1.2928e+00, -1.6349e+00, -1.1511e+00, -9.0430e-04,\n",
      "          1.2438e+00,  2.3233e-01, -9.7487e-01],\n",
      "        [-2.5936e-01,  7.4029e-02,  1.3072e+00, -1.3323e-01, -6.1612e-01,\n",
      "          5.4580e-01, -3.4117e-01, -4.5955e-01],\n",
      "        [ 1.0247e-01,  6.7699e-01, -6.6861e-01,  2.2630e-01, -2.9368e-01,\n",
      "         -1.2636e+00,  1.3476e+00, -4.6094e-01],\n",
      "        [-5.6880e-02,  5.1699e-01,  3.4769e-01,  9.0209e-01,  4.0056e-01,\n",
      "         -1.4741e-01, -1.7207e+00, -5.1751e-01],\n",
      "        [ 3.4654e-01, -6.3015e-01,  3.8711e-01, -7.0938e-01, -1.4822e+00,\n",
      "          2.8392e-01,  1.9146e-01, -4.3963e-01]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3296e+00, -1.7722e+00, -2.0000e+00, -1.2098e+00, -5.1593e-01,\n",
       "          -1.3994e-01,  3.0890e-01,  1.0507e+00],\n",
       "         [ 3.6133e-01,  1.3256e+00, -1.6759e-01, -1.1906e-01,  1.5129e+00,\n",
       "          -6.2672e-01,  5.7583e-01, -5.0284e-01]],\n",
       "\n",
       "        [[-4.0213e-01,  1.4174e+00,  1.0090e+00, -1.6705e+00, -5.1651e-01,\n",
       "           3.5122e-01,  1.4479e+00, -1.0237e+00],\n",
       "         [ 1.7625e-01, -1.2928e+00, -1.6349e+00, -1.1511e+00, -9.0430e-04,\n",
       "           1.2438e+00,  2.3233e-01, -9.7487e-01]],\n",
       "\n",
       "        [[-2.5936e-01,  7.4029e-02,  1.3072e+00, -1.3323e-01, -6.1612e-01,\n",
       "           5.4580e-01, -3.4117e-01, -4.5955e-01],\n",
       "         [ 1.0247e-01,  6.7699e-01, -6.6861e-01,  2.2630e-01, -2.9368e-01,\n",
       "          -1.2636e+00,  1.3476e+00, -4.6094e-01]],\n",
       "\n",
       "        [[-5.6880e-02,  5.1699e-01,  3.4769e-01,  9.0209e-01,  4.0056e-01,\n",
       "          -1.4741e-01, -1.7207e+00, -5.1751e-01],\n",
       "         [ 3.4654e-01, -6.3015e-01,  3.8711e-01, -7.0938e-01, -1.4822e+00,\n",
       "           2.8392e-01,  1.9146e-01, -4.3963e-01]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(8,8)\n",
    "print(t)\n",
    "torch.reshape(t, (-1, 2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern3A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
