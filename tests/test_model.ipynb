{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "wdir = Path.cwd().parent.absolute()\n",
    "sys.path.insert(1, str(wdir))\n",
    "\n",
    "from models.EEGModels import EEGNet, ShallowConvNet, DeepConvNet, EEGNet_ChanRed, CapsEEGNet, TCNet, EEGNet_WT, TCNet_EMD\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.preprocess_DREAMER import DREAMERDataset\n",
    "\n",
    "# dataset = DREAMERDataset('', \"valence\", tfr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block1.0.weight, Parameters: 1024\n",
      "Layer: block1.1.weight, Parameters: 64\n",
      "Layer: block1.1.bias, Parameters: 64\n",
      "Layer: block1.2.weight, Parameters: 7168\n",
      "Layer: block1.3.weight, Parameters: 512\n",
      "Layer: block1.3.bias, Parameters: 512\n",
      "Layer: block2.0.depthwise.weight, Parameters: 8192\n",
      "Layer: block2.0.pointwise.weight, Parameters: 32768\n",
      "Layer: block2.1.weight, Parameters: 64\n",
      "Layer: block2.1.bias, Parameters: 64\n",
      "Layer: dense.weight, Parameters: 512\n",
      "Layer: dense.bias, Parameters: 2\n",
      "Total Parameters: 50946\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet(nb_classes = 2, Chans = 14, Samples = 128, dropoutRate = 0.1, kernLength = 16, F1 = 64, D = 8, F2 = 64, dropoutType = 'Dropout')\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: chan_reduction.weight, Parameters: 504\n",
      "Layer: chan_reduction.bias, Parameters: 36\n",
      "Layer: block1.0.weight, Parameters: 2048\n",
      "Layer: block1.1.weight, Parameters: 64\n",
      "Layer: block1.1.bias, Parameters: 64\n",
      "Layer: block1.2.weight, Parameters: 9216\n",
      "Layer: block1.3.weight, Parameters: 512\n",
      "Layer: block1.3.bias, Parameters: 512\n",
      "Layer: block2.0.depthwise.weight, Parameters: 8192\n",
      "Layer: block2.0.pointwise.weight, Parameters: 32768\n",
      "Layer: block2.1.weight, Parameters: 64\n",
      "Layer: block2.1.bias, Parameters: 64\n",
      "Layer: dense.weight, Parameters: 512\n",
      "Layer: dense.bias, Parameters: 2\n",
      "Total Parameters: 54558\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet_WT(nb_classes = 2, Chans = 14, InnerChans=18, Samples = 128, dropoutRate = 0.1, kernLength = 16, F1 = 64, D = 8, F2 = 64, dropoutType = 'Dropout', nb_freqs=2)\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliengadonneix/anaconda3/envs/intern3A/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712608633180/work/aten/src/ATen/native/Convolution.cpp:1032.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 14, 2, 128)\n",
    "out = model(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: chan_reduction.weight, Parameters: 1488\n",
      "Layer: chan_reduction.bias, Parameters: 24\n",
      "Layer: block1.0.weight, Parameters: 1280\n",
      "Layer: block1.1.weight, Parameters: 64\n",
      "Layer: block1.1.bias, Parameters: 64\n",
      "Layer: block1.2.weight, Parameters: 12288\n",
      "Layer: block1.3.weight, Parameters: 512\n",
      "Layer: block1.3.bias, Parameters: 512\n",
      "Layer: block2.0.depthwise.weight, Parameters: 8192\n",
      "Layer: block2.0.pointwise.weight, Parameters: 32768\n",
      "Layer: block2.1.weight, Parameters: 64\n",
      "Layer: block2.1.bias, Parameters: 64\n",
      "Layer: dense.weight, Parameters: 1152\n",
      "Layer: dense.bias, Parameters: 3\n",
      "Total Parameters: 58475\n"
     ]
    }
   ],
   "source": [
    "model_SEED = EEGNet_ChanRed(nb_classes = 3, Chans = 62, InnerChans=24, Samples = 200, dropoutRate = 0.1, kernLength = 20, F1 = 64, D = 8, F2 = 64, dropoutType = 'Dropout')\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_SEED.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 1, 62, 200)\n",
    "y = model_SEED(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block_1_2.0.weight, Parameters: 512\n",
      "Layer: block_1_2.1.weight, Parameters: 8\n",
      "Layer: block_1_2.1.bias, Parameters: 8\n",
      "Layer: block_1_2.3.weight, Parameters: 224\n",
      "Layer: block_1_2.4.weight, Parameters: 16\n",
      "Layer: block_1_2.4.bias, Parameters: 16\n",
      "Layer: primaryCaps.caps.weight, Parameters: 24576\n",
      "Layer: primaryCaps.caps.bias, Parameters: 256\n",
      "Layer: primaryCaps.caps2.weight, Parameters: 69632\n",
      "Layer: primaryCaps.caps2.bias, Parameters: 256\n",
      "Layer: emotionCaps.W, Parameters: 1048576\n",
      "Layer: fc.weight, Parameters: 16\n",
      "Layer: fc.bias, Parameters: 1\n",
      "Total Parameters: 1144097\n"
     ]
    }
   ],
   "source": [
    "model_capseegnet = CapsEEGNet(nb_classes=2, Chans=14)\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_capseegnet.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n",
      "tensor([[0.4997, 0.5003],\n",
      "        [0.5012, 0.4988],\n",
      "        [0.5007, 0.4993],\n",
      "        [0.4995, 0.5005],\n",
      "        [0.4992, 0.5008],\n",
      "        [0.4998, 0.5002],\n",
      "        [0.4992, 0.5008],\n",
      "        [0.4997, 0.5003]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 1, 14, 128)\n",
    "y = model_capseegnet(x)\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: emd_expansion.weight, Parameters: 1728\n",
      "Layer: emd_expansion.bias, Parameters: 48\n",
      "Layer: PatchPartition.weight, Parameters: 5376\n",
      "Layer: PatchPartition.bias, Parameters: 32\n",
      "Layer: stages.0.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.0.WMSA.linear1.weight, Parameters: 3072\n",
      "Layer: stages.0.WMSA.linear1.bias, Parameters: 96\n",
      "Layer: stages.0.WMSA.linear2.weight, Parameters: 1024\n",
      "Layer: stages.0.WMSA.linear2.bias, Parameters: 32\n",
      "Layer: stages.0.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.0.SWMSA.linear1.weight, Parameters: 3072\n",
      "Layer: stages.0.SWMSA.linear1.bias, Parameters: 96\n",
      "Layer: stages.0.SWMSA.linear2.weight, Parameters: 1024\n",
      "Layer: stages.0.SWMSA.linear2.bias, Parameters: 32\n",
      "Layer: stages.0.ln.weight, Parameters: 32\n",
      "Layer: stages.0.ln.bias, Parameters: 32\n",
      "Layer: stages.0.MLP.ff.0.weight, Parameters: 4096\n",
      "Layer: stages.0.MLP.ff.0.bias, Parameters: 128\n",
      "Layer: stages.0.MLP.ff.2.weight, Parameters: 4096\n",
      "Layer: stages.0.MLP.ff.2.bias, Parameters: 32\n",
      "Layer: stages.1.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.1.WMSA.linear1.weight, Parameters: 12288\n",
      "Layer: stages.1.WMSA.linear1.bias, Parameters: 192\n",
      "Layer: stages.1.WMSA.linear2.weight, Parameters: 4096\n",
      "Layer: stages.1.WMSA.linear2.bias, Parameters: 64\n",
      "Layer: stages.1.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.1.SWMSA.linear1.weight, Parameters: 12288\n",
      "Layer: stages.1.SWMSA.linear1.bias, Parameters: 192\n",
      "Layer: stages.1.SWMSA.linear2.weight, Parameters: 4096\n",
      "Layer: stages.1.SWMSA.linear2.bias, Parameters: 64\n",
      "Layer: stages.1.ln.weight, Parameters: 64\n",
      "Layer: stages.1.ln.bias, Parameters: 64\n",
      "Layer: stages.1.MLP.ff.0.weight, Parameters: 16384\n",
      "Layer: stages.1.MLP.ff.0.bias, Parameters: 256\n",
      "Layer: stages.1.MLP.ff.2.weight, Parameters: 16384\n",
      "Layer: stages.1.MLP.ff.2.bias, Parameters: 64\n",
      "Layer: stages.2.0.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.0.WMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.0.WMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.0.WMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.0.WMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.0.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.0.SWMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.0.SWMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.0.SWMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.0.SWMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.0.ln.weight, Parameters: 128\n",
      "Layer: stages.2.0.ln.bias, Parameters: 128\n",
      "Layer: stages.2.0.MLP.ff.0.weight, Parameters: 65536\n",
      "Layer: stages.2.0.MLP.ff.0.bias, Parameters: 512\n",
      "Layer: stages.2.0.MLP.ff.2.weight, Parameters: 65536\n",
      "Layer: stages.2.0.MLP.ff.2.bias, Parameters: 128\n",
      "Layer: stages.2.1.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.1.WMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.1.WMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.1.WMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.1.WMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.1.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.1.SWMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.1.SWMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.1.SWMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.1.SWMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.1.ln.weight, Parameters: 128\n",
      "Layer: stages.2.1.ln.bias, Parameters: 128\n",
      "Layer: stages.2.1.MLP.ff.0.weight, Parameters: 65536\n",
      "Layer: stages.2.1.MLP.ff.0.bias, Parameters: 512\n",
      "Layer: stages.2.1.MLP.ff.2.weight, Parameters: 65536\n",
      "Layer: stages.2.1.MLP.ff.2.bias, Parameters: 128\n",
      "Layer: stages.2.2.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.2.WMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.2.WMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.2.WMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.2.WMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.2.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.2.2.SWMSA.linear1.weight, Parameters: 49152\n",
      "Layer: stages.2.2.SWMSA.linear1.bias, Parameters: 384\n",
      "Layer: stages.2.2.SWMSA.linear2.weight, Parameters: 16384\n",
      "Layer: stages.2.2.SWMSA.linear2.bias, Parameters: 128\n",
      "Layer: stages.2.2.ln.weight, Parameters: 128\n",
      "Layer: stages.2.2.ln.bias, Parameters: 128\n",
      "Layer: stages.2.2.MLP.ff.0.weight, Parameters: 65536\n",
      "Layer: stages.2.2.MLP.ff.0.bias, Parameters: 512\n",
      "Layer: stages.2.2.MLP.ff.2.weight, Parameters: 65536\n",
      "Layer: stages.2.2.MLP.ff.2.bias, Parameters: 128\n",
      "Layer: stages.3.WMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.3.WMSA.linear1.weight, Parameters: 196608\n",
      "Layer: stages.3.WMSA.linear1.bias, Parameters: 768\n",
      "Layer: stages.3.WMSA.linear2.weight, Parameters: 65536\n",
      "Layer: stages.3.WMSA.linear2.bias, Parameters: 256\n",
      "Layer: stages.3.SWMSA.pos_embeddings, Parameters: 9\n",
      "Layer: stages.3.SWMSA.linear1.weight, Parameters: 196608\n",
      "Layer: stages.3.SWMSA.linear1.bias, Parameters: 768\n",
      "Layer: stages.3.SWMSA.linear2.weight, Parameters: 65536\n",
      "Layer: stages.3.SWMSA.linear2.bias, Parameters: 256\n",
      "Layer: stages.3.ln.weight, Parameters: 256\n",
      "Layer: stages.3.ln.bias, Parameters: 256\n",
      "Layer: stages.3.MLP.ff.0.weight, Parameters: 262144\n",
      "Layer: stages.3.MLP.ff.0.bias, Parameters: 1024\n",
      "Layer: stages.3.MLP.ff.2.weight, Parameters: 262144\n",
      "Layer: stages.3.MLP.ff.2.bias, Parameters: 256\n",
      "Layer: PatchMerging.0.weight, Parameters: 32768\n",
      "Layer: PatchMerging.0.bias, Parameters: 64\n",
      "Layer: PatchMerging.1.weight, Parameters: 131072\n",
      "Layer: PatchMerging.1.bias, Parameters: 128\n",
      "Layer: PatchMerging.2.weight, Parameters: 524288\n",
      "Layer: PatchMerging.2.bias, Parameters: 256\n",
      "Layer: primaryCaps.caps.weight, Parameters: 3538944\n",
      "Layer: primaryCaps.caps.bias, Parameters: 384\n",
      "Layer: primaryCaps.caps2.weight, Parameters: 245760\n",
      "Layer: primaryCaps.caps2.bias, Parameters: 384\n",
      "Layer: emotionCaps.W, Parameters: 98304\n",
      "Total Parameters: 6507612\n"
     ]
    }
   ],
   "source": [
    "model_tcnet = TCNet_EMD(nb_classes=2, Chans=14, nb_freqs=2, kern_emd=12)\n",
    "\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model_tcnet.named_parameters():\n",
    "    layer_params = param.numel()\n",
    "    print(f\"Layer: {name}, Parameters: {layer_params}\")\n",
    "    total_params += layer_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 14, 3, 128)\n",
    "out = model_tcnet(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n",
      "mps\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(os.cpu_count())\n",
    "print(torch.cuda.device_count()) \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(device.type == 'cuda')\n",
    "if device.type == 'cuda':\n",
    "    properties = torch.cuda.get_device_properties(device)\n",
    "    print(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import plistlib\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"Get information about the GPU on macOS.\"\"\"\n",
    "    # Run system_profiler command and capture the output\n",
    "    result = subprocess.run(['system_profiler', '-xml', 'SPDisplaysDataType'], capture_output=True)\n",
    "    if result.returncode == 0:\n",
    "        # Parse the XML output\n",
    "        display_info = plistlib.loads(result.stdout)\n",
    "        # Extract GPU information\n",
    "        gpu_count = len(display_info[0]['_items'])\n",
    "        return gpu_count\n",
    "    else:\n",
    "        print(\"Error:\", result.stderr)\n",
    "        return None\n",
    "\n",
    "gpu_count = get_gpu_info()\n",
    "if gpu_count is not None:\n",
    "    print(\"Number of GPUs:\", gpu_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time:  0.2951338291168213\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# syncrocnize time with cpu, otherwise only time for oflaoding data to gpu would be measured\n",
    "torch.mps.synchronize()\n",
    "\n",
    "a = torch.ones(4000,4000, device=\"mps\")\n",
    "for _ in range(200):\n",
    "   a +=a\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print( \"GPU Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3310, -0.7779, -0.8517,  0.3107,  0.4501, -1.4042,  0.2066,  0.4133],\n",
      "        [-1.2149,  0.9095,  0.6724,  1.6511,  0.6922, -1.2538, -0.2289,  1.0141],\n",
      "        [-0.2060, -1.7363, -2.1075, -1.0517,  1.5688,  0.3479, -0.9671, -1.6473],\n",
      "        [-0.4754,  0.3361,  1.8254, -0.0305,  1.5051,  0.6922,  0.7587, -1.1033],\n",
      "        [ 0.3410,  0.0603,  0.2560,  0.4281,  1.0576,  0.0429, -1.6011, -0.1525],\n",
      "        [-1.6114, -1.3564,  1.1681,  0.1758, -0.0886,  1.2342, -0.1580, -0.5711],\n",
      "        [ 0.7895,  0.1875, -0.6011, -0.7455,  1.7527,  0.6073, -1.6166, -0.7140],\n",
      "        [-0.6812, -0.4708, -0.3051, -1.1373, -1.4031, -1.4501, -0.9560,  2.2691]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3310, -0.7779, -0.8517,  0.3107,  0.4501, -1.4042,  0.2066,\n",
       "           0.4133],\n",
       "         [-1.2149,  0.9095,  0.6724,  1.6511,  0.6922, -1.2538, -0.2289,\n",
       "           1.0141]],\n",
       "\n",
       "        [[-0.2060, -1.7363, -2.1075, -1.0517,  1.5688,  0.3479, -0.9671,\n",
       "          -1.6473],\n",
       "         [-0.4754,  0.3361,  1.8254, -0.0305,  1.5051,  0.6922,  0.7587,\n",
       "          -1.1033]],\n",
       "\n",
       "        [[ 0.3410,  0.0603,  0.2560,  0.4281,  1.0576,  0.0429, -1.6011,\n",
       "          -0.1525],\n",
       "         [-1.6114, -1.3564,  1.1681,  0.1758, -0.0886,  1.2342, -0.1580,\n",
       "          -0.5711]],\n",
       "\n",
       "        [[ 0.7895,  0.1875, -0.6011, -0.7455,  1.7527,  0.6073, -1.6166,\n",
       "          -0.7140],\n",
       "         [-0.6812, -0.4708, -0.3051, -1.1373, -1.4031, -1.4501, -0.9560,\n",
       "           2.2691]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(8,8)\n",
    "print(t)\n",
    "torch.reshape(t, (-1, 2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern3A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
